{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Add, Lambda\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.metrics import Mean\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.image import psnr\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input directory\n",
    "dataset_path = \"../mri_dataset/kaggle_3m/\"\n",
    "output_path = \"../mri_dataset/super_resolved/\"\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Define the target resolution (width, height)\n",
    "target_resolution = (128, 128)\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Define a custom sorting function to sort filenames by numeric part\n",
    "def sort_by_numeric(filename):\n",
    "    return int(''.join(filter(str.isdigit, filename)))\n",
    "\n",
    "# Function to downsample an image\n",
    "def downsample_image(img, target_resolution):\n",
    "    # Apply Gaussian blur\n",
    "    \n",
    "    # Resize using Bicubic interpolation\n",
    "    resized_img = img.resize(target_resolution, Image.BICUBIC)\n",
    "    \n",
    "    return resized_img\n",
    "\n",
    "def downsample_image_blur(img, target_resolution):\n",
    "    # Apply Gaussian blur\n",
    "    img_blurred = img.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "    \n",
    "    # Resize using Bicubic interpolation\n",
    "    resized_img = img_blurred.resize(target_resolution, Image.BICUBIC)\n",
    "    \n",
    "    return resized_img\n",
    "\n",
    "# Iterate over TIFF files in the dataset\n",
    "for patient in os.listdir(dataset_path):#[::10]:\n",
    "    # Iterate over TIFF files for each patient\n",
    "    for tif_file in os.listdir(os.path.join(dataset_path, patient)):#sorted(os.listdir(os.path.join(dataset_path, patient)), key=sort_by_numeric):\n",
    "        if \"_mask\" not in tif_file:  # Filter out \"mask\" images\n",
    "            # Read original image\n",
    "            original_image_path = os.path.join(dataset_path, patient, tif_file)\n",
    "            original_img = Image.open(original_image_path)\n",
    "            \n",
    "            # Downsample the image\n",
    "            downscaled_img = downsample_image_blur(original_img, target_resolution)\n",
    "            # Save the downsampled image to the output directory\n",
    "            output_downscaled_image_path = os.path.join(output_path, patient, tif_file)\n",
    "            #os.makedirs(os.path.dirname(output_downscaled_image_path), exist_ok=True)\n",
    "            #downscaled_img.save(output_downscaled_image_path)\n",
    "            \n",
    "            # Convert image to numpy array and append to training data\n",
    "            original_img_array = np.array(original_img)\n",
    "            downscaled_img_array = np.array(downscaled_img)\n",
    "            X.append(downscaled_img_array)\n",
    "            y.append(original_img_array)\n",
    "\n",
    "# Convert training data to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "X = X.astype('float32') / 255.0\n",
    "y = y.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42)\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# Calculate the number of complete batches that fit\n",
    "num_batches = X_train.shape[0] // batch_size\n",
    "X_train_batches = np.array(np.split(X_train[:num_batches * batch_size],num_batches))\n",
    "y_train_batches = np.array(np.split(y_train[:num_batches * batch_size],num_batches))\n",
    "\n",
    "num_batches_val = X_val.shape[0] // batch_size\n",
    "X_val_batches = np.expand_dims(X_val, axis = 0)\n",
    "y_val_batches = np.expand_dims(y_val, axis = 0)\n",
    "#X_val_batches = np.array(np.split(X_val[:num_batches_val * batch_size],num_batches_val))\n",
    "#y_val_batches = np.array(np.split(y_val[:num_batches_val * batch_size],num_batches_val))\n",
    "\n",
    "# Reshape the array into batches\n",
    "print(y_train_batches.shape)\n",
    "print(y_val_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsamples_per_scale = {\n",
    "    2: 1,\n",
    "    4: 2,\n",
    "    8: 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "    \n",
    "def upsample(x_in, num_filters):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n",
    "    x = Lambda(pixel_shuffle(scale=2))(x)\n",
    "    return PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "\n",
    "def residual_block(block_input, num_filters, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(block_input)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = Add()([block_input, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_srresnet(scale=2, num_filters=64, num_res_blocks=16):\n",
    "    if scale not in upsamples_per_scale:\n",
    "        raise ValueError(f\"available scales are: {upsamples_per_scale.keys()}\")\n",
    "\n",
    "    num_upsamples = upsamples_per_scale[scale]\n",
    "\n",
    "    lr = Input(shape=(None, None, 3))\n",
    "    x = lr\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=9, padding='same')(x)\n",
    "    x = x_1 = PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = residual_block(x, num_filters)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_1, x])\n",
    "\n",
    "    for _ in range(num_upsamples):\n",
    "        x = upsample(x, num_filters * 4)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n",
    "    sr = x#Lambda(denormalize_m11)(x)\n",
    "\n",
    "    return Model(lr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Add, Lambda, LeakyReLU, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "\n",
    "\n",
    "\n",
    "def discriminator_block(x_in, num_filters, strides=1, batchnorm=True, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, strides=strides, padding='same')(x_in)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(momentum=momentum)(x)\n",
    "    return LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\n",
    "def build_discriminator(hr_crop_size):\n",
    "    x_in = Input(shape=(hr_crop_size, hr_crop_size, 3))\n",
    "    x = x_in\n",
    "\n",
    "    x = discriminator_block(x, 64, batchnorm=False)\n",
    "    x = discriminator_block(x, 64, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 128)\n",
    "    x = discriminator_block(x, 128, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 256)\n",
    "    x = discriminator_block(x, 256, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 512)\n",
    "    x = discriminator_block(x, 512, strides=2)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(x_in, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(lr, hr):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        #lr = tf.cast(lr, tf.float32)\n",
    "        #hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "        sr = srgan_checkpoint.generator(lr, training=True)\n",
    "        hr_output = srgan_checkpoint.discriminator(hr, training=True)\n",
    "        sr_output = srgan_checkpoint.discriminator(sr, training=True)\n",
    "        \n",
    "        con_loss = calculate_content_loss(hr, sr)\n",
    "        \n",
    "        gen_loss = calculate_generator_loss(sr_output)\n",
    "        perc_loss = con_loss + 0.001 * gen_loss\n",
    "        disc_loss = calculate_discriminator_loss(hr_output, sr_output)\n",
    "    gradients_of_generator = gen_tape.gradient(perc_loss, srgan_checkpoint.generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, srgan_checkpoint.discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, srgan_checkpoint.generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, srgan_checkpoint.discriminator.trainable_variables))\n",
    "\n",
    "    return perc_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def calculate_content_loss(hr, sr):\n",
    "    hr_255 = hr * 255\n",
    "    hr_255 = tf.round(hr_255)\n",
    "    hr_255 = tf.cast(hr_255, tf.uint16)\n",
    "    sr_255 = sr * 255\n",
    "    sr_255 = tf.round(sr_255)\n",
    "    sr_255 = tf.cast(sr_255, tf.uint16)\n",
    "    \n",
    "    sr_255 = preprocess_input(sr_255)\n",
    "    hr_255 = preprocess_input(hr_255)\n",
    "    sr_features = perceptual_model(sr_255) / 2000\n",
    "    hr_features = perceptual_model(hr_255) / 2000\n",
    "    #return mean_squared_error(hr, sr)\n",
    "    return mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "def calculate_generator_loss(sr_out):\n",
    "    sr_255 = sr_out * 255\n",
    "    sr_255 = tf.round(sr_255)\n",
    "    sr_255 = tf.cast(sr_255, tf.uint16)\n",
    "    return binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "def calculate_discriminator_loss(hr_out, sr_out):\n",
    "    hr_255 = hr_out * 255\n",
    "    hr_255 = tf.round(hr_255)\n",
    "    hr_255 = tf.cast(hr_255, tf.uint16)\n",
    "    sr_255 = sr_out * 255\n",
    "    sr_255 = tf.round(sr_255)\n",
    "    sr_255 = tf.cast(sr_255, tf.uint16)\n",
    "\n",
    "    hr_loss = binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "    sr_loss = binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "    #return mean_squared_error(hr_out, sr_out)\n",
    "    return hr_loss + sr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = target_resolution + (3,)  # (256, 256, 3)\n",
    "#super_resolution_model = build_super_resolution_model(input_shape) #build_generator(input_shape) #\n",
    "generator = build_srresnet(num_res_blocks=16)\n",
    "discriminator = build_discriminator(hr_crop_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5_4 = 20\n",
    "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "perceptual_model = Model(vgg.input, vgg.layers[layer_5_4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                       psnr=tf.Variable(0.0),\n",
    "                                       generator_optimizer=Adam(0.0001),\n",
    "                                       discriminator_optimizer=Adam(0.0001),\n",
    "                                       generator=generator,\n",
    "                                       discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "mean_squared_error = MeanSquaredError()\n",
    "\n",
    "generator_optimizer = Adam(learning_rate=0.0001)\n",
    "discriminator_optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_loss_metric = Mean()\n",
    "discriminator_loss_metric = Mean()\n",
    "\n",
    "sr_out = []\n",
    "step = srgan_checkpoint.step.numpy()\n",
    "step_counter = 0\n",
    "sr_outputs = []\n",
    "hr_outputs = []\n",
    "\n",
    "val_gen_loss_array = []\n",
    "val_con_loss_array = []\n",
    "val_perc_loss_array = []\n",
    "val_disc_loss_array = []\n",
    "\n",
    "now = time.perf_counter()\n",
    "\n",
    "for lr, hr in zip(X_train_batches, y_train_batches):\n",
    "    step = srgan_checkpoint.step.numpy()\n",
    "    step_counter = step_counter + 1\n",
    "\n",
    "    perceptual_loss, discriminator_loss = train_step(lr, hr)\n",
    "    perceptual_loss_metric(perceptual_loss)\n",
    "    discriminator_loss_metric(discriminator_loss)\n",
    "\n",
    "    if step_counter % 100 == 0:\n",
    "        psnr_values = []\n",
    "        sr_out_batch = []\n",
    "        hr_out_batch = []\n",
    "        for lr, hr in zip(X_val_batches, y_val_batches):\n",
    "            #sr = generator.predict(lr[np.newaxis, ...], verbose = 0)[0]\n",
    "            #sr = tf.clip_by_value(sr, 0, 1)\n",
    "            #sr_out_batch.append(sr)\n",
    "            #hr_out_batch.append(hr)\n",
    "\n",
    "            sr = srgan_checkpoint.generator(lr, training=False)\n",
    "            sr = tf.clip_by_value(sr, 0, 1)\n",
    "            hr_output = srgan_checkpoint.discriminator(hr, training=False)\n",
    "            sr_output = srgan_checkpoint.discriminator(sr, training=False)\n",
    "            val_gen_loss = calculate_generator_loss(sr_output)\n",
    "    \n",
    "            val_con_loss = calculate_content_loss(hr, sr)\n",
    "            val_perc_loss = val_con_loss + 0.001 * val_gen_loss\n",
    "            val_disc_loss = calculate_discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "            val_gen_loss_array.append(val_gen_loss)\n",
    "            val_con_loss_array.append(val_con_loss)\n",
    "            val_perc_loss_array.append(val_perc_loss)\n",
    "            val_disc_loss_array.append(val_perc_loss)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(10, 5), dpi = 300)            \n",
    "            axes = axes.flatten()\n",
    "            for i in range(4):\n",
    "                plt.subplot(1, 4, i+1)\n",
    "                plt.imshow(hr[i], clim=[0, 1])\n",
    "                plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            fig.savefig(f\"./SRGAN_images/hr_{step_counter}.png\")\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(10, 5), dpi = 300)            \n",
    "            axes = axes.flatten()\n",
    "            for i in range(4):\n",
    "                plt.subplot(1, 4, i+1)\n",
    "                plt.imshow(sr[i].numpy(), clim=[0, 1])\n",
    "                plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            fig.savefig(f\"./SRGAN_images/sr_{step_counter}.png\")\n",
    "\n",
    "        duration = time.perf_counter() - now\n",
    "        #sr_outputs.append(sr)\n",
    "        now = time.perf_counter()\n",
    "        print(f'{step_counter}, perceptual loss = {val_perc_loss:.4f}, discriminator loss = {val_disc_loss:.4f}, generator loss = {val_gen_loss:.4f} ({duration:.2f}s)')\n",
    "        sr_outputs.append(sr_out_batch)\n",
    "        hr_outputs.append(hr_out_batch)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure and first axes\n",
    "fig, ax1 = plt.subplots(dpi = 300)\n",
    "\n",
    "# Plot losses on the first axis\n",
    "ax1.plot(val_con_loss_array, label='Content Loss')\n",
    "ax1.plot(val_perc_loss_array, label='Perceptual Loss')\n",
    "ax1.plot(val_disc_loss_array, label='Discriminator Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('C, P, D Loss')\n",
    "\n",
    "# Create second axis for generator loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(val_gen_loss_array, color='red', label='Generator Loss')\n",
    "ax2.set_ylabel('G Loss')\n",
    "\n",
    "# Combine legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper right')\n",
    "\n",
    "# Set title\n",
    "plt.title('SRGAN Losses')\n",
    "\n",
    "# Save and display plot\n",
    "plt.savefig(\"SRGAN_losses.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
